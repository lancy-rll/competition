{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615179.ipynb  data  external-libraries\twork\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/66/25/ff030e2437265616a1e9b25ccc864e0371a0bc3adb7c5a404fd661c6f4f6/beautifulsoup4-4.9.1-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 411kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.1 soupsieve-2.0.1\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, you need to use the persistence path as the following:\n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可:\r\n",
    "# Also add the following code, so that every time the environment (kernel) starts, just run the following code:\r\n",
    "import sys\r\n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import seaborn as sbn\r\n",
    "import time\r\n",
    "import math\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('./data/data42684/train.csv')\r\n",
    "test=pd.read_csv('./data/data42684/test.csv')\r\n",
    "songs=pd.read_csv('./data/data42684/songs.csv')\r\n",
    "song_extra=pd.read_csv('./data/data42684/song_extra.csv')\r\n",
    "members=pd.read_csv('./data/data42684/members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7377418, 6, 2556790, 6, 2296320, 7, 2295971, 3, 34403, 7)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape+test.shape+songs.shape+song_extra.shape+members.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_v=train[math.ceil(train.shape[0]*0.8):]\r\n",
    "train_t=train[0:math.ceil(train.shape[0]*0.8)]\r\n",
    "train_v.to_csv('./data/training/validation.csv',index=False)\r\n",
    "train_t.to_csv('./data/training/train.csv',index=False)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1475483, 6, 5901935, 6)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_v.shape+train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import seaborn as sbn\r\n",
    "import time\r\n",
    "import math\r\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('./data/training/train.csv')\r\n",
    "valid_test=pd.read_csv('./data/training/validation.csv')\r\n",
    "test=pd.read_csv('./data/data42684/test.csv')\r\n",
    "songs=pd.read_csv('./data/data42684/songs.csv')\r\n",
    "song_extra=pd.read_csv('./data/data42684/song_extra.csv')\r\n",
    "members=pd.read_csv('./data/data42684/members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song_id_set=set(train['song_id'].append(valid_test['song_id']).append(test['song_id']))#如果把测试集一块分析的话要加入test.csv\r\n",
    "songs['appeared']=songs['song_id'].apply(lambda x: True if x in song_id_set else False)\r\n",
    "songs=songs[songs.appeared]\r\n",
    "songs.drop('appeared',axis=1,inplace=True)\r\n",
    "\r\n",
    "song_extra['appeared']=song_extra['song_id'].apply(lambda x: True if x in song_id_set else False)\r\n",
    "song_extra=song_extra[song_extra.appeared]\r\n",
    "song_extra.drop('appeared',axis=1,inplace=True)\r\n",
    "\r\n",
    "msno_set=set(train['msno'].append(valid_test['msno']).append(test['msno']))#如果把测试集一块分析的话要加入test.csv\r\n",
    "members['appeared']=members['msno'].apply(lambda x: True if x in msno_set else False)\r\n",
    "members=members[members.appeared]\r\n",
    "members.drop('appeared',axis=1,inplace=True)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419781, 7, 419661, 3, 34403, 7)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.shape+song_extra.shape+members.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "members['bd']=members['bd'].apply(lambda x: np.nan if x<=0 or x>=95 else x)\r\n",
    "members['bd_missing']=(members['bd'].isnull())*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_id             0\n",
       "song_length         0\n",
       "genre_ids        9005\n",
       "artist_name         0\n",
       "composer       182563\n",
       "lyricist       316755\n",
       "language            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#songs中的缺失值\r\n",
    "songs['genre_ids'].fillna('0',inplace=True)\r\n",
    "songs['artist_name'].fillna('no_artist_name',inplace=True)\r\n",
    "songs['composer'].fillna('no_composer',inplace=True)\r\n",
    "songs['lyricist'].fillna('no_lyricist',inplace=True)\r\n",
    "\r\n",
    "#填补language中的缺失值\r\n",
    "#songs_temp=songs.loc[songs['language'].isnull()]\r\n",
    "# language_value = (songs.loc[songs['artist_name']==(songs_temp['artist_name'].values)[0]]['language'][0:1].values)[0]\r\n",
    "# songs['language'].fillna(language_value,inplace=True)\r\n",
    "songs['language'].fillna(songs['language'].mode()[0],inplace=True)\r\n",
    "\r\n",
    "#填补members中缺失值\r\n",
    "members['bd'].fillna(members['bd'].median(),inplace=True)\r\n",
    "members['gender'].fillna('Other',inplace=True)\r\n",
    "\r\n",
    "#填补训练集中缺失值\r\n",
    "train['source_system_tab'].fillna(train['source_system_tab'].mode()[0],inplace=True)\r\n",
    "train['source_screen_name'].fillna(train['source_screen_name'].mode()[0],inplace=True)\r\n",
    "train['source_type'].fillna(train['source_type'].mode()[0],inplace=True)\r\n",
    "\r\n",
    "#填补验证集中缺失值\r\n",
    "valid_test['source_system_tab'].fillna(valid_test['source_system_tab'].mode()[0],inplace=True)\r\n",
    "valid_test['source_screen_name'].fillna(valid_test['source_screen_name'].mode()[0],inplace=True)\r\n",
    "valid_test['source_type'].fillna(valid_test['source_type'].mode()[0],inplace=True)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labelencoder编码\r\n",
    "# 对所有的msno做labelEncoder编码\r\n",
    "msno_encoder=LabelEncoder()\r\n",
    "msno_encoder.fit(members['msno'].values)\r\n",
    "members['msno']=msno_encoder.transform(members['msno'])\r\n",
    "train['msno']=msno_encoder.transform(train['msno'])\r\n",
    "valid_test['msno']=msno_encoder.transform(valid_test['msno'])\r\n",
    "test['msno']=msno_encoder.transform(test['msno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 对所有的song_id做labelEncoder编码\r\n",
    "song_id_encoder=LabelEncoder()\r\n",
    "song_id_encoder.fit(train['song_id'].append(valid_test['song_id']).append(test['song_id']))#是test还是valid_test\r\n",
    "songs['song_id']=song_id_encoder.transform(songs['song_id'])\r\n",
    "song_extra['song_id']=song_id_encoder.transform(song_extra['song_id'])\r\n",
    "train['song_id']=song_id_encoder.transform(train['song_id'])\r\n",
    "valid_test['song_id']=song_id_encoder.transform(valid_test['song_id'])#是test还是valid_test\r\n",
    "test['song_id']=song_id_encoder.transform(test['song_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 对train和test中其他类别型变量做labelEncoder编码\r\n",
    "columns = ['source_system_tab', 'source_screen_name', 'source_type']\r\n",
    "for column in columns:\r\n",
    "    column_encoder=LabelEncoder()\r\n",
    "    column_encoder.fit(train[column].append(valid_test[column]))#是test还是valid_test\r\n",
    "    train[column]=column_encoder.transform(train[column])\r\n",
    "    valid_test[column]=column_encoder.transform(valid_test[column])#是test还是valid_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 对members中的city、gender、registered_via做labelEncoder编码\r\n",
    "columns = ['city', 'gender', 'registered_via']\r\n",
    "for column in columns:\r\n",
    "    column_encoder=LabelEncoder()\r\n",
    "    column_encoder.fit(members[column])#是test还是valid_test\r\n",
    "    members[column]=column_encoder.transform(members[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "处理songs中字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 处理genre_ids, 分割成  first_genre_id\r\n",
    "#                      second_genre_id\r\n",
    "#                      third_genre_id\r\n",
    "# 统计一首歌出现的流派数目 genre_id_cnt\r\n",
    "genre_id=np.zeros((len(songs),4))\r\n",
    "for i in range(len(songs)):\r\n",
    "    ids=str(songs['genre_ids'].values[i]).split('|')\r\n",
    "    if len(ids)>2:\r\n",
    "        genre_id[i,0]=int(ids[0])\r\n",
    "        genre_id[i,1]=int(ids[1])\r\n",
    "        genre_id[i,2]=int(ids[2])\r\n",
    "    elif len(ids)>1:\r\n",
    "        genre_id[i,0]=int(ids[0])\r\n",
    "        genre_id[i,1]=int(ids[1])\r\n",
    "    elif len(ids)==1:\r\n",
    "        genre_id[i,0]=int(ids[0])\r\n",
    "    genre_id[i,3]=int(len(ids))\r\n",
    "songs['first_genre_id']=genre_id[:,0]\r\n",
    "songs['second_genre_id']=genre_id[:,1]\r\n",
    "songs['third_genre_id']=genre_id[:,2]\r\n",
    "songs['genre_id_cnt']=genre_id[:,3]\r\n",
    "genre_encoder=LabelEncoder()\r\n",
    "genre_encoder.fit(songs.first_genre_id.append(songs.second_genre_id).append(songs.third_genre_id))\r\n",
    "songs['first_genre_id']=genre_encoder.transform(songs['first_genre_id'])\r\n",
    "songs['second_genre_id']=genre_encoder.transform(songs['second_genre_id'])\r\n",
    "songs['third_genre_id']=genre_encoder.transform(songs['third_genre_id'])\r\n",
    "songs.drop('genre_ids',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#统计每首歌的歌手数目\r\n",
    "def artist_count(x):\r\n",
    "    return x.count('and')+x.count(',')+x.count(' feat')+x.count('&')+1\r\n",
    "songs['artist_cnt']=songs['artist_name'].apply(artist_count).astype(np.int64)\r\n",
    "def get_count(x):\r\n",
    "    try:\r\n",
    "        return sum(map(x.count,['|','/','\\\\',';']))+1\r\n",
    "    except:\r\n",
    "        return 0\r\n",
    "songs['lyricist_cnt']=songs['lyricist'].apply(get_count).astype(np.int64)\r\n",
    "songs['composer_cnt']=songs['composer'].apply(get_count).astype(np.int64)\r\n",
    "songs['is_featured']=songs['artist_name'].apply(lambda x: 1 if ' feat' in str(x) else 0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 歌曲的演唱者只保留第一个\r\n",
    "def get_first_artist(x):\r\n",
    "    if x.count('and')>0:\r\n",
    "        x=x.split('and')[0]\r\n",
    "    if x.count(',')>0:\r\n",
    "        x=x.split(',')[0]\r\n",
    "    if x.count(' feat')>0:\r\n",
    "        x=x.split(' feat')[0]\r\n",
    "    if x.count('&')>0:\r\n",
    "        x=x.split('&')[0]\r\n",
    "    return x.strip()\r\n",
    "songs['artist_name']=songs['artist_name'].apply(get_first_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 歌曲的作词人和作曲人只保留第一个\r\n",
    "def get_first_term(x):\r\n",
    "    if x.count('|')>0:\r\n",
    "        x=x.split('|')[0]\r\n",
    "    if x.count('/')>0:\r\n",
    "        x=x.split('/')[0]\r\n",
    "    if x.count('\\\\')>0:\r\n",
    "        x=x.split('\\\\')[0]\r\n",
    "    if x.count(';')>0:\r\n",
    "        x=x.split(';')[0]\r\n",
    "    return x.strip()\r\n",
    "songs['lyricist']=songs['lyricist'].apply(get_first_term)\r\n",
    "songs['composer']=songs['composer'].apply(get_first_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 对处理后的artist_name、composer、lyricist、language做LabelEncoder        \r\n",
    "columns = ['artist_name', 'lyricist', 'composer','language']\r\n",
    "for column in columns:\r\n",
    "    column_encoder=LabelEncoder()\r\n",
    "    column_encoder.fit(songs[column])\r\n",
    "    songs[column]=column_encoder.transform(songs[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 按演唱者分类，统计每个演唱者唱过几首歌\r\n",
    "artist_song_cnt=songs.groupby(by='artist_name').count()['song_id'].to_dict()\r\n",
    "songs['artist_song_cnt']=songs['artist_name'].apply(lambda x:artist_song_cnt[x] if not np.isnan(x) else np.nan)\r\n",
    "# 按作曲人分类，统计每个作曲人编曲数目\r\n",
    "composer_song_cnt=songs.groupby(by='composer').count()['song_id'].to_dict()\r\n",
    "songs['composer_song_cnt']=songs['composer'].apply(lambda x:composer_song_cnt[x] if not np.isnan(x) else np.nan)\r\n",
    "# 按作词人分类，统计每个作词人作词数目\r\n",
    "lyricist_song_cnt=songs.groupby(by='lyricist').count()['song_id'].to_dict()\r\n",
    "songs['lyricist_song_cnt']=songs['lyricist'].apply(lambda x:lyricist_song_cnt[x] if not np.isnan(x) else np.nan)\r\n",
    "# 按歌曲风格分类，统计每个流派包含多少首歌\r\n",
    "genre_song_cnt=songs.groupby(by='first_genre_id').count()['song_id'].to_dict()\r\n",
    "songs['genre_song_cnt']=songs['first_genre_id'].apply(lambda x:genre_song_cnt[x] if not np.isnan(x) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "处理song_extra中的字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 歌曲出版的国家码 -- cn\r\n",
    "# 歌曲出版者码    -- xxx\r\n",
    "# 歌曲录制年份    -- year \r\n",
    "data = train[['msno', 'song_id']].append(valid_test[['msno', 'song_id']]).append(test[['msno', 'song_id']])\r\n",
    "songs = songs.merge(song_extra, on='song_id', how='left')\r\n",
    "\r\n",
    "isrc = songs['isrc']\r\n",
    "songs['cn'] = isrc.str.slice(0, 2)\r\n",
    "songs['xxx'] = isrc.str.slice(2, 5)\r\n",
    "songs['year'] = isrc.str.slice(5, 7).astype(float)\r\n",
    "# 歌曲录制的年份转换为4位\r\n",
    "songs['year'] = songs['year'].apply(lambda x: 2000+x if x < 18 else 1900+x)\r\n",
    "\r\n",
    "# 增加一个新特征，代表是否isrc缺失\r\n",
    "songs['isrc_missing'] = (songs['cn'].isnull()) * 1.0\r\n",
    "songs['cn'] = LabelEncoder().fit_transform(songs['cn'].fillna('None'))\r\n",
    "songs['xxx'] = LabelEncoder().fit_transform(songs['xxx'].fillna('None'))\r\n",
    "songs['year'].fillna(songs['year'].median(),inplace=True)\r\n",
    "\r\n",
    "# 按国家码分类，统计每个国家码的歌曲数目\r\n",
    "song_cn_cnt = songs.groupby(by='cn').count()['song_id'].to_dict()\r\n",
    "songs['cn_song_cnt'] = songs['cn'].apply(lambda x: song_cn_cnt[x] if not np.isnan(x) else None)\r\n",
    "\r\n",
    "# 按出版码分类，统计每个出版者出版的歌曲数目\r\n",
    "song_xxx_cnt = songs.groupby(by='xxx').count()['song_id'].to_dict()\r\n",
    "songs['xxx_song_cnt'] = songs['xxx'].apply(lambda x: song_xxx_cnt[x] if not np.isnan(x) else None)\r\n",
    "\r\n",
    "# 按歌曲年份分类，统计每个年份录制的歌曲数目\r\n",
    "song_year_cnt = songs.groupby(by='year').count()['song_id'].to_dict()\r\n",
    "songs['year_song_cnt'] = songs['year'].apply(lambda x: song_year_cnt[x] if not np.isnan(x) else None)\r\n",
    "\r\n",
    "data = data.merge(songs, on='song_id', how='left')\r\n",
    "# 按国家码分类，统计每个国家码下有多少用户收听\r\n",
    "song_cn_cnt = data.groupby(by='cn').count()['msno'].to_dict()\r\n",
    "songs['cn_rec_cnt'] = songs['cn'].apply(lambda x: song_cn_cnt[x] if not np.isnan(x) else None)\r\n",
    "\r\n",
    "# 按出版码分类，统计每个出版码下有多少用户收听\r\n",
    "song_xxx_cnt = data.groupby(by='xxx').count()['msno'].to_dict()\r\n",
    "songs['xxx_rec_cnt'] = songs['xxx'].apply(lambda x: song_xxx_cnt[x] if not np.isnan(x) else None)\r\n",
    "\r\n",
    "# 按歌曲年份分类，统计每个年份下有多少用户收听\r\n",
    "song_year_cnt = data.groupby(by='year').count()['msno'].to_dict()\r\n",
    "songs['year_rec_cnt'] = songs['year'].apply(lambda x: song_year_cnt[x] if not np.isnan(x) else None)\r\n",
    "\r\n",
    "features = ['cn_song_cnt', 'xxx_song_cnt', 'year_song_cnt', 'cn_rec_cnt', 'xxx_rec_cnt', 'year_rec_cnt']\r\n",
    "for feat in features:\r\n",
    "    songs[feat] = np.log1p(songs[feat])\r\n",
    "\r\n",
    "songs.drop(['name', 'isrc'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 按歌曲id分类，统计每首歌被播放的用户数目\r\n",
    "song_rec_cnt=data.groupby(by='song_id').count()['msno'].to_dict()\r\n",
    "songs['song_rec_cnt']=songs['song_id'].apply(lambda x:song_rec_cnt[x] if not np.isnan(x) else np.nan)\r\n",
    "# 按演唱者分类，统计每个演唱者被收听过的用户数目\r\n",
    "artist_rec_cnt=data.groupby(by='artist_name').count()['msno'].to_dict()\r\n",
    "songs['artist_rec_cnt']=songs['artist_name'].apply(lambda x:artist_rec_cnt[x] if not np.isnan(x) else np.nan)\r\n",
    "# 按作曲人分类，统计每个作曲人被收听过的用户数目\r\n",
    "composer_rec_cnt=data.groupby(by='composer').count()['msno'].to_dict()\r\n",
    "songs['composer_rec_cnt']=songs['composer'].apply(lambda x:composer_rec_cnt[x] if not np.isnan(x) else np.nan)\r\n",
    "# 按作词人分类，统计每个作词人被收听的用户数目\r\n",
    "lyricist_rec_cnt=data.groupby(by='lyricist').count()['msno'].to_dict()\r\n",
    "songs['lyricist_rec_cnt']=songs['lyricist'].apply(lambda x:lyricist_rec_cnt[x] if not np.isnan(x) else np.nan)\r\n",
    "# 按first_genre_id流派分类，统计每个风格被收听的用户数目\r\n",
    "genre_rec_cnt=data.groupby(by='first_genre_id').count()['msno'].to_dict()\r\n",
    "songs['genre_rec_cnt']=songs['first_genre_id'].apply(lambda x:genre_rec_cnt[x] if not np.isnan(x) else np.nan)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['song_length', 'song_rec_cnt', 'artist_song_cnt', 'composer_song_cnt', \r\n",
    "        'lyricist_song_cnt', 'genre_song_cnt', 'artist_rec_cnt', \r\n",
    "        'composer_rec_cnt', 'lyricist_rec_cnt', 'genre_rec_cnt']\r\n",
    "for feat in features:\r\n",
    "    songs[feat]=np.log1p(songs[feat])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count：训练集里每首歌曲被听取的次数，即该歌曲在数据集中出现的总次数\r\n",
    "# mean：被重复听取的概率（sum(target=1)/count，即一歌曲被用户第二次播放/该歌曲在数据集\r\n",
    "train_merge_songs=train[['msno','song_id','target']].append(valid_test[['msno','song_id','target']]).merge(songs,on='song_id')#valid_test or test\r\n",
    "song_mean_count=train_merge_songs[['song_id','target']].groupby(['song_id']).agg(['mean','count'])\r\n",
    "song_mean_count.reset_index(inplace=True)\r\n",
    "song_mean_count.columns=list(map(''.join,song_mean_count.columns.values))\r\n",
    "song_mean_count.columns=['song_id','repeat_play_chance','plays']\r\n",
    "songs=songs.merge(song_mean_count,on='song_id',how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "处理members中的字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=train[['msno','song_id']].append(valid_test[['msno','song_id']]).append(test[['msno','song_id']])#是valid_test还是test\r\n",
    "# 统计一个用户听过多少首歌(训练集+测试集)\r\n",
    "mem_rec_cnt=data.groupby(by='msno').count()['song_id'].to_dict()\r\n",
    "members['mem_rec_cnt']=members['msno'].apply(lambda x:mem_rec_cnt[x])\r\n",
    "members['mem_rec_cnt']=np.log1p(members['mem_rec_cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 到期时间减去注册时间，得到用户的会员时间，作为新特征加入members\r\n",
    "members['expiration_date']=members['expiration_date'].astype(np.str)\r\n",
    "members['registration_init_time']=members['registration_init_time'].astype(np.str)\r\n",
    "members['membership_days']=pd.to_datetime(members['expiration_date']).subtract(pd.to_datetime(members['registration_init_time'])).dt.days.astype(int)\r\n",
    "# 将registration_init_time拆分成年、月、日，并作为新特征加入到menmbers中\r\n",
    "members['registration_year']=pd.to_datetime(members['registration_init_time']).dt.year\r\n",
    "members['registration_month']=pd.to_datetime(members['registration_init_time']).dt.month\r\n",
    "members['registration_day']=pd.to_datetime(members['registration_init_time']).dt.day\r\n",
    "# 将expiration_date拆分成年、月、日，并作为新特征加入到members中\r\n",
    "members['expiration_year']=pd.to_datetime(members['expiration_date']).dt.year\r\n",
    "members['expiration_month']=pd.to_datetime(members['expiration_date']).dt.month\r\n",
    "members['expiration_day']=pd.to_datetime(members['expiration_date']).dt.day\r\n",
    "members['registration_init_time']=members['registration_init_time'].apply(lambda x: time.mktime(time.strptime(str(x),'%Y%m%d')))\r\n",
    "members['expiration_date']=members['expiration_date'].apply(lambda x: time.mktime(time.strptime(str(x),'%Y%m%d')))\r\n",
    "members=members.drop(['registration_init_time','expiration_date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 对train和test中的相关source的三个字段做独热编码, 并计算相关概率\r\n",
    "dummy_feat = ['source_system_tab', 'source_screen_name', 'source_type']\r\n",
    "concat_train_test=train.drop('target',axis=1).append(valid_test.drop('target',axis=1))\r\n",
    "for feat in dummy_feat:\r\n",
    "    dummies=pd.get_dummies(concat_train_test[feat])\r\n",
    "    dummies.columns=['msno_%s_'%feat+'%s'%col for col in dummies.columns]\r\n",
    "    dummies['msno']=concat_train_test['msno'].values\r\n",
    "    dummies=dummies.groupby('msno').mean()\r\n",
    "    dummies.reset_index()\r\n",
    "    members=members.merge(dummies,on='msno',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.to_csv('./data/training/train_validation_r1.csv',index=False)\r\n",
    "valid_test.to_csv('./data/training/test_validation_r1.csv',index=False)\r\n",
    "members.to_csv('./data/training/members_validation_r1.csv',index=False)\r\n",
    "songs.to_csv('./data/training/songs_validation_r1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "增加后验概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 把用户的所有特征合并到训练集和验证集中\r\n",
    "train_temp=train.merge(members,on='msno',how='left')\r\n",
    "valid_test_temp=valid_test.merge(members,on='msno',how='left')\r\n",
    "# 查找训练集和验证集中包含‘source_system_tab’字符的特征\r\n",
    "train_source_system_tab=train_temp[[col for col in train_temp.columns if 'source_system_tab' in col]]\r\n",
    "valid_test_source_system_tab=valid_test_temp[[col for col in valid_test_temp.columns if 'source_system_tab' in col]]\r\n",
    "# 查找训练集和验证集中包含‘source_screen_name’字符的特征\r\n",
    "train_source_screen_name=train_temp[[col for col in train_temp.columns if 'source_screen_name' in col]]\r\n",
    "valid_test_source_screen_name=valid_test_temp[[col for col in valid_test_temp.columns if 'source_screen_name' in col]]\r\n",
    "# 查找训练集和验证集中包含‘source_type’字符的特征\r\n",
    "train_source_type=train_temp[[col for col in train_temp.columns if 'source_type' in col]]\r\n",
    "valid_test_source_type=valid_test_temp[[col for col in valid_test_temp.columns if 'source_type' in col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['msno_source_system_tab_prob']=train_source_system_tab.apply(lambda x:x['msno_source_system_tab_%d'%x['source_system_tab']],axis=1)\r\n",
    "valid_test['msno_source_system_tab_prob']=valid_test_source_system_tab.apply(lambda x:x['msno_source_system_tab_%d'%x['source_system_tab']],axis=1)\r\n",
    "train['msno_source_screen_name_prob']=train_source_screen_name.apply(lambda x:x['msno_source_screen_name_%d'%x['source_screen_name']],axis=1)\r\n",
    "valid_test['msno_source_screen_name_prob']=valid_test_source_screen_name.apply(lambda x:x['msno_source_screen_name_%d'%x['source_screen_name']],axis=1)\r\n",
    "train['msno_source_type_prob']=train_source_type.apply(lambda x:x['msno_source_type_%d'%x['source_type']],axis=1)\r\n",
    "valid_test['msno_source_type_prob']=valid_test_source_type.apply(lambda x:x['msno_source_type_%d'%x['source_type']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.to_csv('./work/training/train_validation_prob.csv',index=False)\r\n",
    "valid_test.to_csv('./work/training/valid_test_validation_prob.csv',index=False)\r\n",
    "members.to_csv('./work/training/members_validation_prob.csv',index=False)\r\n",
    "songs.to_csv('./work/training/songs_validation_prob.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "用户-歌曲关系矩阵分解、用户-歌手关系矩阵分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import seaborn as sbn\r\n",
    "import time\r\n",
    "import math\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from scipy import sparse\r\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('work/training/train_validation_prob.csv')\r\n",
    "valid_test=pd.read_csv('work/training/valid_test_validation_prob.csv')\r\n",
    "members=pd.read_csv('work/training/members_validation_prob.csv')\r\n",
    "songs=pd.read_csv('work/training/songs_validation_prob.csv')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7377418\n"
     ]
    }
   ],
   "source": [
    "concat = train[['msno', 'song_id']].append(valid_test[['msno', 'song_id']])\r\n",
    "member_cnt = concat['msno'].max() + 1\r\n",
    "song_cnt = concat['song_id'].max() + 1\r\n",
    "artist_cnt = int(songs['artist_name'].max() + 1)\r\n",
    "print(len(concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[929.19644441 348.80981297 309.40275499 252.8020833  235.66103789\n",
      " 184.89734987 178.8854274  163.36788383 158.45152867 151.20234554\n",
      " 147.54990949 146.69235095 141.14892669 132.07849752 129.90593115\n",
      " 125.32091035 122.28441182 119.65531332 117.63870037 115.73739365\n",
      " 113.58651385 112.08390834 111.2969255  109.59026882 108.62116088\n",
      " 106.05728495 105.57023407 102.20677814 101.28490626 100.46536012\n",
      "  97.84094794  96.92911592  96.04246875  95.87283229  93.84138743\n",
      "  92.73973012  91.85405027  90.3989575   89.84799528  89.29548723\n",
      "  88.31527645  88.11258867  86.453424    86.01874769  84.99338776\n",
      "  84.59675956  83.97524489  83.40244589]\n"
     ]
    }
   ],
   "source": [
    "# 设计用户-歌曲关系矩阵，并做SVD分解成三个矩阵\r\n",
    "n_component = 48\r\n",
    "\r\n",
    "data = np.ones(len(concat))\r\n",
    "msno = concat['msno'].values\r\n",
    "song_id = concat['song_id'].values\r\n",
    "\r\n",
    "rating = sparse.coo_matrix((data, (msno, song_id)))\r\n",
    "rating = (rating > 0) * 1.0\r\n",
    "\r\n",
    "[u, s, vt] = svds(rating, k=n_component)\r\n",
    "print(s[::-1])\r\n",
    "s_song = np.diag(s[::-1])\r\n",
    "\r\n",
    "# 保留跟用户相关的48维特征，存入members表中\r\n",
    "members_topics = pd.DataFrame(u[:, ::-1])\r\n",
    "members_topics.columns = ['member_component_%d'%i for i in range(n_component)]\r\n",
    "members_topics['msno'] = range(member_cnt)\r\n",
    "members = members.merge(members_topics, on='msno', how='right')\r\n",
    "\r\n",
    "# 保留跟歌曲相关的48维特征，存入songs表中\r\n",
    "song_topics = pd.DataFrame(vt.transpose()[:, ::-1])\r\n",
    "song_topics.columns = ['song_component_%d'%i for i in range(n_component)]\r\n",
    "song_topics['song_id'] = range(song_cnt)\r\n",
    "songs = songs.merge(song_topics, on='song_id', how='right')\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7377304\n",
      "[1231.90585798  405.63937345  303.7062179   278.05664389  243.94539539\n",
      "  214.25753678  175.36567621  172.69229575  157.80083028  153.16554079\n",
      "  149.3448921   146.934055    138.7035043   135.44997276  132.95733285\n",
      "  126.14460143]\n"
     ]
    }
   ],
   "source": [
    "# 设计用户-歌曲关系矩阵，并做SVD分解成三个矩阵 \r\n",
    "n_component = 16\r\n",
    "\r\n",
    "concat = concat.merge(songs[['song_id', 'artist_name']], on='song_id', how='left')\r\n",
    "concat = concat[concat['artist_name'] >= 0]\r\n",
    "msno = concat['msno'].values\r\n",
    "artist = concat['artist_name'].values.astype(int)\r\n",
    "\r\n",
    "print(len(concat))\r\n",
    "data = np.ones(len(concat))\r\n",
    "rating_tmp = sparse.coo_matrix((data, (msno, artist)))\r\n",
    "\r\n",
    "rating = np.log1p(rating_tmp) * 0.3 + (rating_tmp > 0) * 1.0\r\n",
    "\r\n",
    "[u, s, vt] = svds(rating, k=n_component)\r\n",
    "print(s[::-1])\r\n",
    "s_artist = np.diag(s[::-1])\r\n",
    "\r\n",
    "# 保留跟用户相关的16维特征，存入members表中\r\n",
    "members_topics = pd.DataFrame(u[:, ::-1])\r\n",
    "members_topics.columns = ['member_artist_component_%d'%i for i in range(n_component)]\r\n",
    "members_topics['msno'] = range(member_cnt)\r\n",
    "members = members.merge(members_topics, on='msno', how='left')\r\n",
    "\r\n",
    "# 保留跟artist name相关的16维特征，存入songs表中\r\n",
    "artist_topics = pd.DataFrame(vt.transpose()[:, ::-1])\r\n",
    "artist_topics.columns = ['artist_component_%d'%i for i in range(n_component)]\r\n",
    "artist_topics['artist_name'] = range(artist_cnt)\r\n",
    "songs = songs.merge(artist_topics, on='artist_name', how='left')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 增加新特征\r\n",
    "members = members.sort_values(by='msno')\r\n",
    "songs = songs.sort_values(by='song_id')\r\n",
    "\r\n",
    "mem_cols = ['member_component_%d'%i for i in range(48)]\r\n",
    "song_cols = ['song_component_%d'%i for i in range(48)]\r\n",
    "members.columns\r\n",
    "member_embeddings = members[mem_cols].values\r\n",
    "song_embeddings = songs[song_cols].values\r\n",
    "\r\n",
    "mem_cols = ['member_artist_component_%d'%i for i in range(16)]\r\n",
    "song_cols = ['artist_component_%d'%i for i in range(16)]\r\n",
    "\r\n",
    "member_artist_embeddings = members[mem_cols].values\r\n",
    "song_artist_embeddings = songs[song_cols].values\r\n",
    "\r\n",
    "train_dot = np.zeros((len(train), 2))\r\n",
    "valid_test_dot = np.zeros((len(valid_test), 2))\r\n",
    "\r\n",
    "for i in range(len(train)):\r\n",
    "    msno_idx = train['msno'].values[i]\r\n",
    "    song_idx = train['song_id'].values[i]\r\n",
    "    \r\n",
    "    train_dot[i, 0] = np.dot(member_embeddings[msno_idx], np.dot(s_song, song_embeddings[song_idx]))\r\n",
    "    train_dot[i, 1] = np.dot(member_artist_embeddings[msno_idx], np.dot(s_artist, song_artist_embeddings[song_idx]))\r\n",
    "\r\n",
    "for i in range(len(valid_test)):\r\n",
    "    msno_idx = valid_test['msno'].values[i]\r\n",
    "    song_idx = valid_test['song_id'].values[i]\r\n",
    "    \r\n",
    "    valid_test_dot[i, 0] = np.dot(member_embeddings[msno_idx], np.dot(s_song, song_embeddings[song_idx]))\r\n",
    "    valid_test_dot[i, 1] = np.dot(member_artist_embeddings[msno_idx], np.dot(s_artist, song_artist_embeddings[song_idx]))\r\n",
    "\r\n",
    "train['song_embeddings_dot'] = train_dot[:, 0]\r\n",
    "train['artist_embeddings_dot'] = train_dot[:, 1]\r\n",
    "\r\n",
    "valid_test['song_embeddings_dot'] = valid_test_dot[:, 0]\r\n",
    "valid_test['artist_embeddings_dot'] = valid_test_dot[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存SVD结果的文件\r\n",
    "train.to_csv('work/training/train_validation_svd.csv', index=False)\r\n",
    "valid_test.to_csv('work/training/valid_test_validation_svd.csv', index=False)\r\n",
    "members.to_csv('work/training/members_validation_svd.csv', index=False)\r\n",
    "songs.to_csv('work/training/songs_validation_svd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('work/training/train_validation_svd.csv')\r\n",
    "valid_test=pd.read_csv('work/training/valid_test_validation_svd.csv')\r\n",
    "members=pd.read_csv('work/training/members_validation_svd.csv')\r\n",
    "songs=pd.read_csv('work/training/songs_validation_svd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存数据集\r\n",
    "train.to_csv('work/training/train_final.csv',index=False,float_format='%.6f')\r\n",
    "valid_test.to_csv('work/training/valid_test_final.csv',index=False,float_format='%.6f')\r\n",
    "members.to_csv('work/training/members_gbdt.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['composer', 'lyricist', 'language', 'first_genre_id', 'second_genre_id', 'third_genre_id']\r\n",
    "for col in columns:\r\n",
    "    songs[col].fillna(0,inplace=True)\r\n",
    "    songs[col]=songs[col].astype(int)\r\n",
    "songs['artist_name'].fillna((songs['artist_name'].max())+1,inplace=True)\r\n",
    "songs['artist_name']=songs['artist_name'].astype(int)\r\n",
    "songs['isrc_missing'].fillna(0,inplace=True)\r\n",
    "songs['isrc_missing']=songs['isrc_missing'].astype(int)\r\n",
    "songs.to_csv('work/training/songs_gbdt.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songs['song_id_missiing']=np.isnan(songs['song_length'].values)*1\r\n",
    "columns = ['song_length', 'genre_id_cnt', 'artist_cnt', 'lyricist_cnt', 'composer_cnt', 'is_featured',\r\n",
    "           'artist_song_cnt', 'composer_song_cnt', 'lyricist_song_cnt', 'genre_song_cnt', 'song_rec_cnt', \r\n",
    "           'artist_rec_cnt', 'composer_rec_cnt', 'lyricist_rec_cnt', 'genre_rec_cnt', 'cn', 'xxx', 'year', \r\n",
    "           'cn_song_cnt', 'xxx_song_cnt', 'year_song_cnt', 'cn_rec_cnt', 'xxx_rec_cnt', 'year_rec_cnt', \r\n",
    "           'repeat_play_chance','plays'] + ['artist_component_%d'%i for i in range(16)]\r\n",
    "for col in columns:\r\n",
    "    songs[col].fillna(np.nanmean(songs[col]),inplace=True)\r\n",
    "songs.to_csv('work/training/songs_validation_nn.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\r\n",
    "import math\r\n",
    "import time\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from collections import defaultdict\r\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('work/training/train_validation_svd.csv')\r\n",
    "valid_test=pd.read_csv('work/training/valid_test_validation_svd.csv')\r\n",
    "members=pd.read_csv('work/training/members_validation_svd.csv')\r\n",
    "songs=pd.read_csv('work/training/songs_validation_svd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\r\n",
    "# pd.set_option('display.width', None)\r\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5901935, 11, 1475483, 11, 34403, 118, 419839, 99)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "      \r\n",
    "      train.shape+valid_test.shape+members.shape+songs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练集和测试集的数目作为索引\r\n",
    "concat=train[['msno','song_id']].append(valid_test[['msno','song_id']])\r\n",
    "concat['timestamp']=range(len(concat))\r\n",
    "## windows_based count\r\n",
    "window_sizes = [10, 25, 500, 5000, 10000, 50000]\r\n",
    "msno_list=concat['msno'].values\r\n",
    "song_list=concat['song_id'].values\r\n",
    "def get_window_cnt(values,idx,window_size):\r\n",
    "    lower=max(0,idx-window_size)\r\n",
    "    upper=min(len(values),idx+window_size)\r\n",
    "    return (values[lower:idx]==values[idx]).sum(),(values[idx:upper]==values[idx]).sum()\r\n",
    "# 得到不同窗口的前后相同用户或者歌曲个数\r\n",
    "for window_size in window_sizes:\r\n",
    "    msno_before_cnt=np.zeros(len(concat))\r\n",
    "    song_before_cnt = np.zeros(len(concat))\r\n",
    "    msno_after_cnt = np.zeros(len(concat))\r\n",
    "    song_after_cnt = np.zeros(len(concat))\r\n",
    "    for i in range(len(concat)):\r\n",
    "        msno_before_cnt[i],msno_after_cnt[i]=get_window_cnt(msno_list,i,window_size)\r\n",
    "        song_before_cnt[i],song_after_cnt[i]=get_window_cnt(song_list,i,window_size)\r\n",
    "    concat['msno_%d_before_cnt'%window_size]=msno_before_cnt\r\n",
    "    concat['song_%d_before_cnt'%window_size] = song_before_cnt\r\n",
    "    concat['msno_%d_after_cnt'%window_size] = msno_after_cnt\r\n",
    "    concat['song_%d_after_cnt'%window_size] = song_after_cnt\r\n",
    "# 统计当前用户和当前歌曲，相同的样本数\r\n",
    "msno_dict = defaultdict(lambda: 0)\r\n",
    "song_dict = defaultdict(lambda: 0)\r\n",
    "\r\n",
    "msno_till_now_cnt = np.zeros(len(concat))\r\n",
    "song_till_now_cnt = np.zeros(len(concat))\r\n",
    "for i in range(len(concat)):\r\n",
    "    msno_till_now_cnt[i] = msno_dict[msno_list[i]]\r\n",
    "    msno_dict[msno_list[i]] += 1\r\n",
    "    \r\n",
    "    song_till_now_cnt[i] = song_dict[song_list[i]]\r\n",
    "    song_dict[song_list[i]] += 1\r\n",
    "\r\n",
    "concat['msno_till_now_cnt'] = msno_till_now_cnt\r\n",
    "concat['song_till_now_cnt'] = song_till_now_cnt\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['msno_till_now_cnt', 'song_till_now_cnt']\r\n",
    "for window_size in window_sizes:\r\n",
    "    features += ['msno_%d_before_cnt'%window_size, 'song_%d_before_cnt'%window_size, \r\n",
    "            'msno_%d_after_cnt'%window_size, 'song_%d_after_cnt'%window_size]\r\n",
    "for feat in features:\r\n",
    "    concat[feat] = np.log1p(concat[feat])\r\n",
    "\r\n",
    "# 得到增加特征后的训练集和测试集\r\n",
    "#features = ['timestamp'] + features\r\n",
    "data = concat[features].values\r\n",
    "\r\n",
    "for i in range(len(features)):\r\n",
    "    train[features[i]] = data[:len(train), i]\r\n",
    "    valid_test[features[i]] = data[len(train):, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存中间结果\r\n",
    "train.to_csv('work/training/train_svd_.csv',index=False)\r\n",
    "valid_test.to_csv('work/training/valid_test_svd_.csv',index=False)\r\n",
    "members.to_csv('work/training/members_svd_.csv',index=False)\r\n",
    "songs.to_csv('work/training/songs_svd_.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri Jan 13 00:00:00 2017'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.asctime(time.localtime(1484236800.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Aug 15 00:00:00 2016'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.asctime(time.localtime(1471190400.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-897e5e530ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 增加新特征，每个用户收听歌曲的时间点的标准差。值越大说明用户收听的跨度越大\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmsno_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'msno'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmembers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msno_timestamp_std'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msno'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmsno_std\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 增加新特征，每首歌被收听的时间点的平均值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-897e5e530ed9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 增加新特征，每个用户收听歌曲的时间点的标准差。值越大说明用户收听的跨度越大\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmsno_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'msno'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmembers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msno_timestamp_std'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msno'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmsno_std\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 增加新特征，每首歌被收听的时间点的平均值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# 计算当前记录所处的相对时间点\r\n",
    "def timestamp_map(x):\r\n",
    "    x = (x - 0.0) / (7377417.0 - 0.0) * (1484236800.0 - 1471190400.0) + 1471190400.0\r\n",
    "    return x\r\n",
    "    \r\n",
    "concat['timestamp'] = concat['timestamp'].apply(timestamp_map)\r\n",
    "\r\n",
    "# 增加新特征，每个用户收听歌曲的时间点的平均值\r\n",
    "msno_mean = concat.groupby(by='msno').mean()['timestamp'].to_dict()\r\n",
    "members['msno_timestamp_mean'] = members['msno'].apply(lambda x: msno_mean[x] if x in msno_mean else concat['timestamp'].mode()[0])\r\n",
    "\r\n",
    "# 增加新特征，每个用户收听歌曲的时间点的标准差。值越大说明用户收听的跨度越大\r\n",
    "msno_std = concat.groupby(by='msno').std()['timestamp'].to_dict()\r\n",
    "members['msno_timestamp_std'] = members['msno'].apply(lambda x: msno_std[x])\r\n",
    "\r\n",
    "# 增加新特征，每首歌被收听的时间点的平均值\r\n",
    "song_mean = concat.groupby(by='song_id').mean()['timestamp'].to_dict()\r\n",
    "songs['song_timestamp_mean'] = songs['song_id'].apply(lambda x: song_mean[x])\r\n",
    "\r\n",
    "# 增加新特征，每首歌被收听时间点的标准差。值越大，说明歌曲被收听的时间跨度大\r\n",
    "song_std = concat.groupby(by='song_id').std()['timestamp'].to_dict()\r\n",
    "songs['song_timestamp_std'] = songs['song_id'].apply(lambda x: song_std[x])\r\n",
    "\r\n",
    "print('Timestamp done.')\r\n",
    "\r\n",
    "features = ['msno_till_now_cnt', 'song_till_now_cnt']\r\n",
    "for window_size in window_sizes:\r\n",
    "    features += ['msno_%d_before_cnt'%window_size, 'song_%d_before_cnt'%window_size, \r\n",
    "            'msno_%d_after_cnt'%window_size, 'song_%d_after_cnt'%window_size]\r\n",
    "for feat in features:\r\n",
    "    concat[feat] = np.log1p(concat[feat])\r\n",
    "\r\n",
    "# 得到增加特征后的训练集和测试集\r\n",
    "features = ['timestamp'] + features\r\n",
    "data = concat[features].values\r\n",
    "\r\n",
    "for i in range(len(features)):\r\n",
    "    train[features[i]] = data[:len(train), i]\r\n",
    "    test[features[i]] = data[len(train):, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\r\n",
    "import math\r\n",
    "import time\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('work/training/train_svd_.csv')\r\n",
    "valid_test=pd.read_csv('work/training/valid_test_svd_.csv')\r\n",
    "members=pd.read_csv('work/training/members_svd_.csv')\r\n",
    "songs=pd.read_csv('work/training/songs_svd_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['composer', 'lyricist', 'language', 'first_genre_id', 'second_genre_id', 'third_genre_id','isrc_missing']\r\n",
    "for col in columns:\r\n",
    "    songs[col].fillna(0,inplace=True)\r\n",
    "    songs[col]=songs[col].astype(int)\r\n",
    "songs['artist_name'].fillna(np.max(songs['artist_name'])+1,inplace=True)\r\n",
    "songs['artist_name']=songs['artist_name'].astype(int)\r\n",
    "songs['song_id_missing']=np.isnan(songs['song_length'].values)*1\r\n",
    "columns = ['song_length', 'genre_id_cnt', 'artist_song_cnt', 'composer_song_cnt', \r\n",
    "       'lyricist_song_cnt', 'genre_song_cnt', 'song_rec_cnt', \r\n",
    "       'artist_rec_cnt', 'composer_rec_cnt', 'lyricist_rec_cnt', \r\n",
    "       'genre_rec_cnt','cn','xxx','year', 'cn_song_cnt', \r\n",
    "       'xxx_song_cnt', 'year_song_cnt', 'cn_rec_cnt', 'xxx_rec_cnt', \r\n",
    "       'year_rec_cnt',  'artist_cnt', 'lyricist_cnt', \r\n",
    "       'composer_cnt', 'is_featured'] + ['artist_component_%d'%i for i in range(16)]\r\n",
    "for col in columns:\r\n",
    "    songs[col].fillna(np.nanmean(songs[col]),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songs.to_csv('work/music/songs_val_nn.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#members['msno_timestamp_std'].fillna(np.nanmin(members['msno_timestamp_std']), inplace=True)\r\n",
    "\r\n",
    "concat = train[['msno', 'song_id', 'source_system_tab', 'source_screen_name', \r\n",
    "        'source_type']].append(valid_test[['msno', 'song_id', 'source_system_tab', \r\n",
    "        'source_screen_name', 'source_type']])\r\n",
    "concat = concat.merge(songs[['song_id', 'song_length', 'artist_name', 'first_genre_id', \r\n",
    "        'artist_rec_cnt', 'song_rec_cnt', 'artist_song_cnt', 'xxx', 'year', \r\n",
    "        'language']], on='song_id', how='left')\r\n",
    "concat['source'] = concat['source_system_tab'] * 10000 + concat['source_screen_name'] * 100 + concat['source_type']\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "concat['source'] = LabelEncoder().fit_transform(concat['source'].values)\r\n",
    "\r\n",
    "mem_add = pd.DataFrame({'msno': range(concat['msno'].max()+1)})\r\n",
    "data_avg = concat[['msno', 'song_length', 'artist_song_cnt', \r\n",
    "        'artist_rec_cnt', 'song_rec_cnt', 'year']].groupby('msno').mean()\r\n",
    "data_avg.columns = ['msno_'+i+'_mean' for i in data_avg.columns]\r\n",
    "# data_avg['msno'] = data_avg.index.values\r\n",
    "data_avg.reset_index()\r\n",
    "members = members.merge(data_avg, on='msno', how='left')\r\n",
    "data_std=concat[['msno', 'song_length', 'artist_song_cnt', \r\n",
    "        'artist_rec_cnt', 'song_rec_cnt', 'year']].groupby('msno').std()\r\n",
    "data_std.columns=['msno_'+i+'_std' for i in data_std.columns]\r\n",
    "data_std.reset_index()\r\n",
    "members=members.merge(data_std,on='msno',how='left')\r\n",
    "#计算msno所属的不同artist_name的个数\r\n",
    "#按msno分类，统计每个用户听过的歌手个数\r\n",
    "artist_msno=concat[['msno', 'artist_name']].groupby('msno').apply(lambda x:len(set(x['artist_name'].values)))\r\n",
    "mem_add['artist_msno_cnt']=artist_msno\r\n",
    "mem_add['artist_msno_cnt']=np.log1p(mem_add['artist_msno_cnt'])\r\n",
    "#计算用户所属的language中不同取值的概率\r\n",
    "language_dummy=pd.get_dummies(concat['language'])\r\n",
    "language_dummy['msno']=concat['msno'].values\r\n",
    "language_prob=language_dummy.groupby('msno').mean()\r\n",
    "language_prob.columns=['msno_language_%d'%i for i in language_prob.columns]\r\n",
    "language_prob.reset_index()\r\n",
    "members=members.merge(language_prob,on='msno',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 生成最终用户信息表\r\n",
    "members.to_csv('work/music/members_val_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# 一些歌曲属性\r\n",
    "col = ['artist_name', 'first_genre_id', 'xxx', 'language', 'year', 'source']\r\n",
    "\r\n",
    "# 统计msno-artist_name， msno-first_genre_id, msno-xxx,msno-language, msno-year, msno-source数据对在数据集中的出现次数\r\n",
    "for feat in col:\r\n",
    "    concat['id'] = concat['msno'] * 100000 + concat[feat]\r\n",
    "    id_cnt = concat[['msno', 'id']].groupby('id').count().to_dict()['msno']\r\n",
    "    concat['msno_'+feat+'_cnt'] = concat['id'].apply(lambda x: id_cnt[x])\r\n",
    "# 统计这些数据对在每个用户收听过的总歌曲里的概率，即出现次数/每个用户收听过的歌曲总数\r\n",
    "msno_cnt=concat[['msno','song_id']].groupby('msno').count().to_dict()['song_id']\r\n",
    "concat['msno_cnt']=concat['msno'].apply(lambda x:msno_cnt[x])\r\n",
    "for feat in col:\r\n",
    "    concat['msno_'+feat+'_prob']=concat['msno_'+feat+'_cnt']/concat['msno_cnt']\r\n",
    "# 统计song_id-source_system_tab，song_id-source_screen_name, song_id-source_type数据对在数据集中的出现次数\r\n",
    "cols = ['source_system_tab', 'source_screen_name', 'source_type']\r\n",
    "for col in cols:\r\n",
    "    concat['id']=concat['song_id']*10000+concat[col]\r\n",
    "    id_cnt=concat[['msno','id']].groupby('id').count().to_dict()['msno']\r\n",
    "    concat['song_'+col+'_cnt']=concat['id'].apply(lambda x:id_cnt[x])\r\n",
    "# 统计每首歌曲被收听的用户总数\r\n",
    "song_cnt=concat[['msno','song_id']].groupby('song_id').count().to_dict()['msno']\r\n",
    "concat['song_cnt']=concat['song_id'].apply(lambda x:song_cnt[x])\r\n",
    "# 统计数据对在每首歌曲被收听的用户总数的概率，即出现次数/每首歌曲被收听的用户总数\r\n",
    "for col in cols:\r\n",
    "    concat['song_'+col+'_prob']=concat['song_'+col+'_cnt']/concat['song_cnt']\r\n",
    "result = concat[['msno_artist_name_prob', 'msno_first_genre_id_prob', 'msno_xxx_prob', \r\n",
    "        'msno_language_prob', 'msno_year_prob', 'song_source_system_tab_prob', \r\n",
    "        'song_source_screen_name_prob', 'song_source_type_prob', 'source', 'msno_source_prob']]\r\n",
    "result['source']=result['source'].astype('category')\r\n",
    "for col in result.columns:\r\n",
    "    train[col]=result[col].values[:len(train)]\r\n",
    "    valid_test[col]=result[col].values[len(train):]\r\n",
    "train['artist_embeddings_dot'].fillna(train['artist_embeddings_dot'].mean(), inplace=True)\r\n",
    "valid_test['artist_embeddings_dot'].fillna(valid_test['artist_embeddings_dot'].mean(), inplace=True)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 生成最后训练集和验证集/测试集\r\n",
    "train.to_csv('work/music/train_val_nn.csv', index=False)\r\n",
    "valid_test.to_csv('work/music/valid_test_val_nn.csv', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b34ab2247e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import sys\r\n",
    "sys.path.append('/home/aistudio/package')\r\n",
    "\r\n",
    "import gc\r\n",
    "import math\r\n",
    "import datetime\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
