{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data45317\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music\r\n"
     ]
    }
   ],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, you need to use the persistence path as the following:\n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可:\n",
    "# Also add the following code, so that every time the environment (kernel) starts, just run the following code:\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/aistudio/package')\n",
    "\n",
    "import gc\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all=pd.read_csv('/home/aistudio/data/data45317/train_val_nn.csv')\n",
    "test_all=pd.read_csv('/home/aistudio/data/data45317/validtestvalnn.csv')\n",
    "members=pd.read_csv('/home/aistudio/data/data45317/members_val_nn.csv')\n",
    "songs=pd.read_csv('/home/aistudio/data/data45317/songs_val_nn.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5901935, 47, 1475483, 47, 34403, 139, 419839, 100)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.shape+test_all.shape+members.shape+songs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=members.isnull().columns\n",
    "for col in columns:\n",
    "    members[col].fillna(np.nanmin(members[col]),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members.to_csv('work/music/members_val_nn.csv',index=False)\n",
    "train_all.to_csv('work/music/train_val_nn.csv',index=False)\n",
    "test_all.to_csv('work/music/valid_test_val_nn.csv',index=False)\n",
    "songs.to_csv('work/music/songs_val_nn.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.read_csv('work/music/train_val_nn.csv')\n",
    "test_all = pd.read_csv('work/music/valid_test_val_nn.csv')\n",
    "members = pd.read_csv('work/music/members_val_nn.csv')\n",
    "songs = pd.read_csv('work/music/songs_val_nn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5901935, 47, 1475483, 47, 34403, 139, 419839, 100)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.shape+test_all.shape+members.shape+songs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 分别取50%训练集和验证集数据(各约300万数据)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train=train_all[math.ceil(train_all.shape[0]*0.5):]\n",
    "test=test_all[0:math.ceil(train_all.shape[0]*0.5)]\n",
    "train_y=train['target']\n",
    "train.drop(['target'],inplace=True,axis=1)\n",
    "test_y=test['target']\n",
    "test.drop(['target'],inplace=True,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.merge(members,on='msno',how='left')\n",
    "test=test.merge(members,on='msno',how='left')\n",
    "train=train.merge(songs,on='song_id',how='left')\n",
    "test=test.merge(songs,on='song_id',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2950967, 283, 1475483, 283)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape+test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del members\n",
    "del songs\n",
    "gc.collect()\n",
    "train_data=lgbm.Dataset(train,label=train_y,free_raw_data=True)\n",
    "test_data=lgbm.Dataset(test,label=test_y,free_raw_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2950967, 283, 1475483, 283)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape+test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[100]\ttrain's binary_logloss: 0.522958\ttrain's auc: 0.814631\tvalid's binary_logloss: 0.565703\tvalid's auc: 0.75402\n",
      "[200]\ttrain's binary_logloss: 0.49575\ttrain's auc: 0.838696\tvalid's binary_logloss: 0.560291\tvalid's auc: 0.760735\n",
      "[300]\ttrain's binary_logloss: 0.478032\ttrain's auc: 0.85321\tvalid's binary_logloss: 0.558618\tvalid's auc: 0.763405\n",
      "[400]\ttrain's binary_logloss: 0.465314\ttrain's auc: 0.863142\tvalid's binary_logloss: 0.558471\tvalid's auc: 0.764308\n",
      "[500]\ttrain's binary_logloss: 0.454432\ttrain's auc: 0.871394\tvalid's binary_logloss: 0.558733\tvalid's auc: 0.764722\n",
      "[600]\ttrain's binary_logloss: 0.444824\ttrain's auc: 0.87851\tvalid's binary_logloss: 0.559121\tvalid's auc: 0.764902\n",
      "[700]\ttrain's binary_logloss: 0.436097\ttrain's auc: 0.884797\tvalid's binary_logloss: 0.559713\tvalid's auc: 0.764882\n",
      "[800]\ttrain's binary_logloss: 0.428164\ttrain's auc: 0.890405\tvalid's binary_logloss: 0.56039\tvalid's auc: 0.764778\n",
      "[900]\ttrain's binary_logloss: 0.420563\ttrain's auc: 0.895671\tvalid's binary_logloss: 0.561001\tvalid's auc: 0.764706\n",
      "[1000]\ttrain's binary_logloss: 0.413596\ttrain's auc: 0.900451\tvalid's binary_logloss: 0.561493\tvalid's auc: 0.764682\n",
      "[1100]\ttrain's binary_logloss: 0.406749\ttrain's auc: 0.904956\tvalid's binary_logloss: 0.562296\tvalid's auc: 0.764474\n",
      "[1200]\ttrain's binary_logloss: 0.400337\ttrain's auc: 0.909189\tvalid's binary_logloss: 0.562884\tvalid's auc: 0.764366\n",
      "[1300]\ttrain's binary_logloss: 0.394347\ttrain's auc: 0.913058\tvalid's binary_logloss: 0.563601\tvalid's auc: 0.764157\n",
      "Early stopping, best iteration is:\n",
      "[361]\ttrain's binary_logloss: 0.469776\ttrain's auc: 0.859675\tvalid's binary_logloss: 0.558398\tvalid's auc: 0.764118\n",
      "best n_estimators: 659\n",
      "Training loss: 0.43957, Validation loss: 0.55933\n",
      "Training AUC: 0.88238,Validation AUC: 0.76501\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'bossting_type':'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric':['binary_logloss','auc'],\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':180,\n",
    "    'max_depth':10,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction':0.8,\n",
    "    'min_gain_to_split': 0,\n",
    "}\n",
    "evals_result={}\n",
    "res=lgbm.train(params,train_data,num_boost_round=6000,valid_sets=[train_data,test_data],valid_names=['train','valid'],\n",
    "evals_result=evals_result,early_stopping_rounds=1000,verbose_eval=100)\n",
    "best_round=np.argmax(evals_result['valid']['auc'])\n",
    "train_auc=evals_result['train']['auc'][best_round]\n",
    "train_loss=evals_result['train']['binary_logloss'][best_round]\n",
    "val_auc=evals_result['valid']['auc'][best_round]\n",
    "val_loss=evals_result['valid']['binary_logloss'][best_round]\n",
    "print('best n_estimators:',best_round)\n",
    "print('Training loss: %.5f, Validation loss: %.5f'%(train_loss,val_loss))\n",
    "print('Training AUC: %.5f,Validation AUC: %.5f'%(train_auc,val_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[100]\ttrain's binary_logloss: 0.524624\ttrain's auc: 0.812714\tvalid's binary_logloss: 0.565644\tvalid's auc: 0.75405\n",
      "[200]\ttrain's binary_logloss: 0.499166\ttrain's auc: 0.835504\tvalid's binary_logloss: 0.560243\tvalid's auc: 0.76071\n",
      "[300]\ttrain's binary_logloss: 0.482803\ttrain's auc: 0.848956\tvalid's binary_logloss: 0.558836\tvalid's auc: 0.763065\n",
      "[400]\ttrain's binary_logloss: 0.470888\ttrain's auc: 0.858342\tvalid's binary_logloss: 0.558393\tvalid's auc: 0.764393\n",
      "[500]\ttrain's binary_logloss: 0.46019\ttrain's auc: 0.866455\tvalid's binary_logloss: 0.558393\tvalid's auc: 0.765258\n",
      "[600]\ttrain's binary_logloss: 0.451097\ttrain's auc: 0.87318\tvalid's binary_logloss: 0.558675\tvalid's auc: 0.765687\n",
      "[700]\ttrain's binary_logloss: 0.443058\ttrain's auc: 0.878931\tvalid's binary_logloss: 0.559121\tvalid's auc: 0.765923\n",
      "[800]\ttrain's binary_logloss: 0.43552\ttrain's auc: 0.884267\tvalid's binary_logloss: 0.559564\tvalid's auc: 0.766097\n",
      "[900]\ttrain's binary_logloss: 0.428604\ttrain's auc: 0.889046\tvalid's binary_logloss: 0.56017\tvalid's auc: 0.766139\n",
      "[1000]\ttrain's binary_logloss: 0.421975\ttrain's auc: 0.893519\tvalid's binary_logloss: 0.560781\tvalid's auc: 0.766138\n",
      "[1100]\ttrain's binary_logloss: 0.415696\ttrain's auc: 0.89767\tvalid's binary_logloss: 0.56146\tvalid's auc: 0.766124\n",
      "[1200]\ttrain's binary_logloss: 0.409665\ttrain's auc: 0.901649\tvalid's binary_logloss: 0.562038\tvalid's auc: 0.76609\n",
      "[1300]\ttrain's binary_logloss: 0.403963\ttrain's auc: 0.905312\tvalid's binary_logloss: 0.562666\tvalid's auc: 0.766024\n",
      "[1400]\ttrain's binary_logloss: 0.398272\ttrain's auc: 0.90894\tvalid's binary_logloss: 0.563399\tvalid's auc: 0.765828\n",
      "Early stopping, best iteration is:\n",
      "[498]\ttrain's binary_logloss: 0.460417\ttrain's auc: 0.866283\tvalid's binary_logloss: 0.558378\tvalid's auc: 0.765253\n",
      "best n_estimators: 1075\n",
      "Training loss: 0.41724, Validation loss: 0.56122\n",
      "Training AUC: 0.89669,Validation AUC: 0.76618\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'bossting_type':'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric':['binary_logloss','auc'],\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':180,\n",
    "    'min_data_in_leaf':1000,\n",
    "    'max_depth':10,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction':0.8,\n",
    "    'min_gain_to_split': 0,\n",
    "}\n",
    "evals_result={}\n",
    "res=lgbm.train(params,train_data,num_boost_round=6000,valid_sets=[train_data,test_data],valid_names=['train','valid'],\n",
    "evals_result=evals_result,early_stopping_rounds=1000,verbose_eval=100)\n",
    "best_round=np.argmax(evals_result['valid']['auc'])\n",
    "train_auc=evals_result['train']['auc'][best_round]\n",
    "train_loss=evals_result['train']['binary_logloss'][best_round]\n",
    "val_auc=evals_result['valid']['auc'][best_round]\n",
    "val_loss=evals_result['valid']['binary_logloss'][best_round]\n",
    "print('best n_estimators:',best_round)\n",
    "print('Training loss: %.5f, Validation loss: %.5f'%(train_loss,val_loss))\n",
    "print('Training AUC: %.5f,Validation AUC: %.5f'%(train_auc,val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[100]\ttrain's binary_logloss: 0.544665\ttrain's auc: 0.79288\tvalid's binary_logloss: 0.571055\tvalid's auc: 0.748347\n",
      "[200]\ttrain's binary_logloss: 0.524206\ttrain's auc: 0.812636\tvalid's binary_logloss: 0.56367\tvalid's auc: 0.756581\n",
      "[300]\ttrain's binary_logloss: 0.511306\ttrain's auc: 0.824399\tvalid's binary_logloss: 0.560655\tvalid's auc: 0.760197\n",
      "[400]\ttrain's binary_logloss: 0.501418\ttrain's auc: 0.833025\tvalid's binary_logloss: 0.559078\tvalid's auc: 0.762335\n",
      "[500]\ttrain's binary_logloss: 0.493537\ttrain's auc: 0.839705\tvalid's binary_logloss: 0.558338\tvalid's auc: 0.763529\n",
      "[600]\ttrain's binary_logloss: 0.486725\ttrain's auc: 0.845296\tvalid's binary_logloss: 0.557855\tvalid's auc: 0.764476\n",
      "[700]\ttrain's binary_logloss: 0.480357\ttrain's auc: 0.850429\tvalid's binary_logloss: 0.557575\tvalid's auc: 0.765158\n",
      "[800]\ttrain's binary_logloss: 0.474597\ttrain's auc: 0.855026\tvalid's binary_logloss: 0.557462\tvalid's auc: 0.765659\n",
      "[900]\ttrain's binary_logloss: 0.469088\ttrain's auc: 0.859308\tvalid's binary_logloss: 0.557404\tvalid's auc: 0.766082\n",
      "[1000]\ttrain's binary_logloss: 0.46386\ttrain's auc: 0.863288\tvalid's binary_logloss: 0.557501\tvalid's auc: 0.766376\n",
      "[1100]\ttrain's binary_logloss: 0.459071\ttrain's auc: 0.866911\tvalid's binary_logloss: 0.557614\tvalid's auc: 0.766611\n",
      "[1200]\ttrain's binary_logloss: 0.454662\ttrain's auc: 0.870223\tvalid's binary_logloss: 0.557686\tvalid's auc: 0.76684\n",
      "[1300]\ttrain's binary_logloss: 0.45038\ttrain's auc: 0.87335\tvalid's binary_logloss: 0.557879\tvalid's auc: 0.766984\n",
      "[1400]\ttrain's binary_logloss: 0.446232\ttrain's auc: 0.876375\tvalid's binary_logloss: 0.558123\tvalid's auc: 0.767063\n",
      "[1500]\ttrain's binary_logloss: 0.442202\ttrain's auc: 0.879258\tvalid's binary_logloss: 0.558401\tvalid's auc: 0.767108\n",
      "[1600]\ttrain's binary_logloss: 0.438326\ttrain's auc: 0.882002\tvalid's binary_logloss: 0.558656\tvalid's auc: 0.767161\n",
      "[1700]\ttrain's binary_logloss: 0.434706\ttrain's auc: 0.884533\tvalid's binary_logloss: 0.558944\tvalid's auc: 0.767154\n",
      "[1800]\ttrain's binary_logloss: 0.431206\ttrain's auc: 0.886976\tvalid's binary_logloss: 0.559286\tvalid's auc: 0.767103\n",
      "Early stopping, best iteration is:\n",
      "[889]\ttrain's binary_logloss: 0.469689\ttrain's auc: 0.858853\tvalid's binary_logloss: 0.557373\tvalid's auc: 0.766083\n",
      "best n_estimators: 1648\n",
      "Training loss: 0.43655, Validation loss: 0.55877\n",
      "Training AUC: 0.88323,Validation AUC: 0.76719\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'bossting_type':'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric':['binary_logloss','auc'],\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':180,\n",
    "    'min_data_in_leaf':1000,\n",
    "    'max_depth':10,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction':0.8,\n",
    "    'min_gain_to_split': 0,\n",
    "    'lambda_l1': 6,\n",
    "    'lambda_l2': 2000\n",
    "}\n",
    "evals_result={}\n",
    "res=lgbm.train(params,train_data,num_boost_round=6000,valid_sets=[train_data,test_data],valid_names=['train','valid'],\n",
    "evals_result=evals_result,early_stopping_rounds=1000,verbose_eval=100)\n",
    "best_round=np.argmax(evals_result['valid']['auc'])\n",
    "train_auc=evals_result['train']['auc'][best_round]\n",
    "train_loss=evals_result['train']['binary_logloss'][best_round]\n",
    "val_auc=evals_result['valid']['auc'][best_round]\n",
    "val_loss=evals_result['valid']['binary_logloss'][best_round]\n",
    "print('best n_estimators:',best_round)\n",
    "print('Training loss: %.5f, Validation loss: %.5f'%(train_loss,val_loss))\n",
    "print('Training AUC: %.5f,Validation AUC: %.5f'%(train_auc,val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[100]\ttrain's binary_logloss: 0.544204\ttrain's auc: 0.793483\tvalid's binary_logloss: 0.570987\tvalid's auc: 0.74852\n",
      "[200]\ttrain's binary_logloss: 0.523954\ttrain's auc: 0.81288\tvalid's binary_logloss: 0.563622\tvalid's auc: 0.75664\n",
      "[300]\ttrain's binary_logloss: 0.511308\ttrain's auc: 0.824392\tvalid's binary_logloss: 0.560759\tvalid's auc: 0.760075\n",
      "[400]\ttrain's binary_logloss: 0.501482\ttrain's auc: 0.832991\tvalid's binary_logloss: 0.559214\tvalid's auc: 0.762138\n",
      "[500]\ttrain's binary_logloss: 0.493586\ttrain's auc: 0.839686\tvalid's binary_logloss: 0.558331\tvalid's auc: 0.763475\n",
      "[600]\ttrain's binary_logloss: 0.486611\ttrain's auc: 0.845387\tvalid's binary_logloss: 0.557877\tvalid's auc: 0.764391\n",
      "[700]\ttrain's binary_logloss: 0.480473\ttrain's auc: 0.850301\tvalid's binary_logloss: 0.55759\tvalid's auc: 0.765107\n",
      "[800]\ttrain's binary_logloss: 0.474996\ttrain's auc: 0.854651\tvalid's binary_logloss: 0.557459\tvalid's auc: 0.765612\n",
      "[900]\ttrain's binary_logloss: 0.469372\ttrain's auc: 0.859036\tvalid's binary_logloss: 0.557453\tvalid's auc: 0.766015\n",
      "[1000]\ttrain's binary_logloss: 0.46432\ttrain's auc: 0.862904\tvalid's binary_logloss: 0.557537\tvalid's auc: 0.766288\n",
      "[1100]\ttrain's binary_logloss: 0.45949\ttrain's auc: 0.866554\tvalid's binary_logloss: 0.557601\tvalid's auc: 0.766539\n",
      "[1200]\ttrain's binary_logloss: 0.454903\ttrain's auc: 0.869999\tvalid's binary_logloss: 0.557783\tvalid's auc: 0.766668\n",
      "[1300]\ttrain's binary_logloss: 0.450508\ttrain's auc: 0.873221\tvalid's binary_logloss: 0.557962\tvalid's auc: 0.766814\n",
      "[1400]\ttrain's binary_logloss: 0.446303\ttrain's auc: 0.876278\tvalid's binary_logloss: 0.558245\tvalid's auc: 0.766858\n",
      "[1500]\ttrain's binary_logloss: 0.442415\ttrain's auc: 0.879089\tvalid's binary_logloss: 0.558498\tvalid's auc: 0.766928\n",
      "[1600]\ttrain's binary_logloss: 0.43863\ttrain's auc: 0.881788\tvalid's binary_logloss: 0.558825\tvalid's auc: 0.766908\n",
      "[1700]\ttrain's binary_logloss: 0.43485\ttrain's auc: 0.88445\tvalid's binary_logloss: 0.559077\tvalid's auc: 0.766981\n",
      "[1800]\ttrain's binary_logloss: 0.431398\ttrain's auc: 0.886881\tvalid's binary_logloss: 0.559454\tvalid's auc: 0.766865\n",
      "Early stopping, best iteration is:\n",
      "[859]\ttrain's binary_logloss: 0.471607\ttrain's auc: 0.857313\tvalid's binary_logloss: 0.557412\tvalid's auc: 0.765903\n",
      "best n_estimators: 1696\n",
      "Training loss: 0.43496, Validation loss: 0.55907\n",
      "Training AUC: 0.88437,Validation AUC: 0.76698\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'bossting_type':'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric':['binary_logloss','auc'],\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':180,\n",
    "    'min_data_in_leaf':1000,\n",
    "    'max_depth':10,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction':0.8,\n",
    "    'min_gain_to_split': 0,  \n",
    "     'lambda_l1': 5,\n",
    "    'lambda_l2': 2000\n",
    "}\n",
    "evals_result={}\n",
    "res=lgbm.train(params,train_data,num_boost_round=6000,valid_sets=[train_data,test_data],valid_names=['train','valid'],\n",
    "evals_result=evals_result,early_stopping_rounds=1000,verbose_eval=100)\n",
    "best_round=np.argmax(evals_result['valid']['auc'])\n",
    "train_auc=evals_result['train']['auc'][best_round]\n",
    "train_loss=evals_result['train']['binary_logloss'][best_round]\n",
    "val_auc=evals_result['valid']['auc'][best_round]\n",
    "val_loss=evals_result['valid']['binary_logloss'][best_round]\n",
    "print('best n_estimators:',best_round)\n",
    "print('Training loss: %.5f, Validation loss: %.5f'%(train_loss,val_loss))\n",
    "print('Training AUC: %.5f,Validation AUC: %.5f'%(train_auc,val_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上调参结果选择最优的一组超参数：验证集上分数是0.76719\n",
    "{ 'bossting_type':'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric':['binary_logloss','auc'],\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':180,\n",
    "    'min_data_in_leaf':1000,\n",
    "    'max_depth':10,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction':0.8,\n",
    "    'min_gain_to_split': 0,\n",
    "    'lambda_l1': 6,\n",
    "    'lambda_l2': 2000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('work/music/train.csv')\n",
    "# test = pd.read_csv('work/music/test.csv')\n",
    "val_test=pd.read_csv('work/music/valid_test_val_nn.csv')\n",
    "val_train=pd.read_csv('work/music/train_val_nn.csv')\n",
    "members = pd.read_csv('work/music/members_val_nn.csv')\n",
    "songs = pd.read_csv('work/music/songs_val_nn.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5901935, 47, 1475483, 47, 34403, 139, 419839, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_train.shape+val_test.shape+members.shape+songs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train=val_train[math.ceil(val_train.shape[0]*0.7):]\n",
    "test=val_test[:]\n",
    "test.drop(['target'],inplace=True,axis=1)\n",
    "train_y=train['target']\n",
    "train.drop(['target'],inplace=True,axis=1)\n",
    "train=train.merge(members,on='msno',how='left')\n",
    "test=test.merge(members,on='msno',how='left')\n",
    "train=train.merge(songs,on='song_id',how='left')\n",
    "test=test.merge(songs,on='song_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1770580, 283, 1475483, 283)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape+test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=lgbm.Dataset(train,label=train_y,free_raw_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 取训练集中最后30%的数据，进行第一次模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.544013\ttraining's auc: 0.79119\n",
      "[200]\ttraining's binary_logloss: 0.522318\ttraining's auc: 0.812551\n",
      "[300]\ttraining's binary_logloss: 0.507018\ttraining's auc: 0.826782\n",
      "[400]\ttraining's binary_logloss: 0.495182\ttraining's auc: 0.837247\n",
      "[500]\ttraining's binary_logloss: 0.485786\ttraining's auc: 0.845168\n",
      "[600]\ttraining's binary_logloss: 0.477371\ttraining's auc: 0.852117\n",
      "[700]\ttraining's binary_logloss: 0.469926\ttraining's auc: 0.858061\n",
      "[800]\ttraining's binary_logloss: 0.462991\ttraining's auc: 0.863443\n",
      "[900]\ttraining's binary_logloss: 0.456611\ttraining's auc: 0.868302\n",
      "[1000]\ttraining's binary_logloss: 0.450433\ttraining's auc: 0.872942\n",
      "[1100]\ttraining's binary_logloss: 0.444605\ttraining's auc: 0.877222\n",
      "[1200]\ttraining's binary_logloss: 0.439106\ttraining's auc: 0.881202\n",
      "[1300]\ttraining's binary_logloss: 0.43385\ttraining's auc: 0.885001\n",
      "[1400]\ttraining's binary_logloss: 0.428903\ttraining's auc: 0.888455\n",
      "[1500]\ttraining's binary_logloss: 0.424103\ttraining's auc: 0.891763\n",
      "[1600]\ttraining's binary_logloss: 0.419517\ttraining's auc: 0.894893\n",
      "[1700]\ttraining's binary_logloss: 0.414994\ttraining's auc: 0.897961\n",
      "[1800]\ttraining's binary_logloss: 0.41079\ttraining's auc: 0.900754\n",
      "[1900]\ttraining's binary_logloss: 0.406675\ttraining's auc: 0.90346\n",
      "[2000]\ttraining's binary_logloss: 0.40261\ttraining's auc: 0.906111\n",
      "[2100]\ttraining's binary_logloss: 0.398684\ttraining's auc: 0.908625\n",
      "[2200]\ttraining's binary_logloss: 0.394891\ttraining's auc: 0.911037\n",
      "[2300]\ttraining's binary_logloss: 0.391165\ttraining's auc: 0.913373\n",
      "[2400]\ttraining's binary_logloss: 0.387524\ttraining's auc: 0.915623\n",
      "[2500]\ttraining's binary_logloss: 0.384013\ttraining's auc: 0.917761\n",
      "[2600]\ttraining's binary_logloss: 0.38055\ttraining's auc: 0.919859\n",
      "[2700]\ttraining's binary_logloss: 0.377164\ttraining's auc: 0.92189\n",
      "[2800]\ttraining's binary_logloss: 0.373893\ttraining's auc: 0.923828\n",
      "[2900]\ttraining's binary_logloss: 0.37065\ttraining's auc: 0.925744\n",
      "[3000]\ttraining's binary_logloss: 0.367434\ttraining's auc: 0.92764\n",
      "[3100]\ttraining's binary_logloss: 0.364336\ttraining's auc: 0.929388\n",
      "[3200]\ttraining's binary_logloss: 0.36132\ttraining's auc: 0.931137\n",
      "[3300]\ttraining's binary_logloss: 0.358331\ttraining's auc: 0.932818\n",
      "[3400]\ttraining's binary_logloss: 0.355332\ttraining's auc: 0.934464\n",
      "[3500]\ttraining's binary_logloss: 0.352398\ttraining's auc: 0.93609\n",
      "[3600]\ttraining's binary_logloss: 0.34958\ttraining's auc: 0.937626\n",
      "[3700]\ttraining's binary_logloss: 0.346804\ttraining's auc: 0.939129\n",
      "[3800]\ttraining's binary_logloss: 0.344071\ttraining's auc: 0.940568\n",
      "[3900]\ttraining's binary_logloss: 0.341389\ttraining's auc: 0.942011\n",
      "[4000]\ttraining's binary_logloss: 0.338747\ttraining's auc: 0.943409\n",
      "[4100]\ttraining's binary_logloss: 0.33615\ttraining's auc: 0.944751\n",
      "[4200]\ttraining's binary_logloss: 0.333552\ttraining's auc: 0.946103\n",
      "[4300]\ttraining's binary_logloss: 0.331048\ttraining's auc: 0.947351\n",
      "[4400]\ttraining's binary_logloss: 0.328549\ttraining's auc: 0.94861\n",
      "[4500]\ttraining's binary_logloss: 0.326071\ttraining's auc: 0.949854\n",
      "[4600]\ttraining's binary_logloss: 0.32362\ttraining's auc: 0.951048\n",
      "[4700]\ttraining's binary_logloss: 0.32126\ttraining's auc: 0.95218\n",
      "[4800]\ttraining's binary_logloss: 0.318945\ttraining's auc: 0.953314\n",
      "[4900]\ttraining's binary_logloss: 0.316621\ttraining's auc: 0.954439\n",
      "[5000]\ttraining's binary_logloss: 0.314352\ttraining's auc: 0.955495\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'bossting_type':'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric':['binary_logloss','auc'],\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':180,\n",
    "    'min_data_in_leaf':1000,\n",
    "    'max_depth':10,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction':0.8,\n",
    "    'min_gain_to_split': 0,\n",
    "    'lambda_l1': 6,\n",
    "    'lambda_l2': 2000\n",
    "}\n",
    "evals_result={}\n",
    "gbm=lgbm.train(params,train_data,num_boost_round=5000,valid_sets=train_data,\n",
    "evals_result=evals_result,verbose_eval=100)\n",
    "feature_importance=pd.DataFrame({'name':gbm.feature_name(),'importance':gbm.feature_importance()}).sort_values(by='importance',ascending=False)\n",
    "feature_importance.to_csv('work/feature_importance/feat_importance_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as cPickle\n",
    "cPickle.dump(gbm,open('work/music_lightgbm/submit_A.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取训练集中50%-70%位置的数据，进行第二次模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train=val_train[math.ceil(val_train.shape[0]*0.5):math.ceil(val_train.shape[0]*0.7)]\n",
    "test=val_test[:]\n",
    "test.drop(['target'],inplace=True,axis=1)\n",
    "train_y=train['target']\n",
    "train.drop(['target'],inplace=True,axis=1)\n",
    "train=train.merge(members,on='msno',how='left')\n",
    "test=test.merge(members,on='msno',how='left')\n",
    "train=train.merge(songs,on='song_id',how='left')\n",
    "test=test.merge(songs,on='song_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=lgbm.Dataset(train,label=train_y,free_raw_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.536405\ttraining's auc: 0.805599\n",
      "[200]\ttraining's binary_logloss: 0.51137\ttraining's auc: 0.828243\n",
      "[300]\ttraining's binary_logloss: 0.494537\ttraining's auc: 0.842348\n",
      "[400]\ttraining's binary_logloss: 0.481468\ttraining's auc: 0.852779\n",
      "[500]\ttraining's binary_logloss: 0.470924\ttraining's auc: 0.860728\n",
      "[600]\ttraining's binary_logloss: 0.461322\ttraining's auc: 0.86782\n",
      "[700]\ttraining's binary_logloss: 0.452855\ttraining's auc: 0.873909\n",
      "[800]\ttraining's binary_logloss: 0.44527\ttraining's auc: 0.879236\n",
      "[900]\ttraining's binary_logloss: 0.438154\ttraining's auc: 0.884125\n",
      "[1000]\ttraining's binary_logloss: 0.431605\ttraining's auc: 0.888598\n",
      "[1100]\ttraining's binary_logloss: 0.42517\ttraining's auc: 0.892903\n",
      "[1200]\ttraining's binary_logloss: 0.419126\ttraining's auc: 0.896857\n",
      "[1300]\ttraining's binary_logloss: 0.413464\ttraining's auc: 0.900512\n",
      "[1400]\ttraining's binary_logloss: 0.408027\ttraining's auc: 0.903944\n",
      "[1500]\ttraining's binary_logloss: 0.402827\ttraining's auc: 0.907252\n",
      "[1600]\ttraining's binary_logloss: 0.397822\ttraining's auc: 0.910321\n",
      "[1700]\ttraining's binary_logloss: 0.392904\ttraining's auc: 0.913288\n",
      "[1800]\ttraining's binary_logloss: 0.388292\ttraining's auc: 0.916068\n",
      "[1900]\ttraining's binary_logloss: 0.383604\ttraining's auc: 0.918834\n",
      "[2000]\ttraining's binary_logloss: 0.3792\ttraining's auc: 0.92141\n",
      "[2100]\ttraining's binary_logloss: 0.37496\ttraining's auc: 0.923894\n",
      "[2200]\ttraining's binary_logloss: 0.370745\ttraining's auc: 0.92629\n",
      "[2300]\ttraining's binary_logloss: 0.36673\ttraining's auc: 0.928546\n",
      "[2400]\ttraining's binary_logloss: 0.362774\ttraining's auc: 0.930745\n",
      "[2500]\ttraining's binary_logloss: 0.359005\ttraining's auc: 0.932797\n",
      "[2600]\ttraining's binary_logloss: 0.355211\ttraining's auc: 0.934818\n",
      "[2700]\ttraining's binary_logloss: 0.351532\ttraining's auc: 0.936761\n",
      "[2800]\ttraining's binary_logloss: 0.34793\ttraining's auc: 0.938706\n",
      "[2900]\ttraining's binary_logloss: 0.344472\ttraining's auc: 0.940515\n",
      "[3000]\ttraining's binary_logloss: 0.340998\ttraining's auc: 0.942296\n",
      "[3100]\ttraining's binary_logloss: 0.337662\ttraining's auc: 0.94399\n",
      "[3200]\ttraining's binary_logloss: 0.334385\ttraining's auc: 0.945619\n",
      "[3300]\ttraining's binary_logloss: 0.331179\ttraining's auc: 0.947244\n",
      "[3400]\ttraining's binary_logloss: 0.327999\ttraining's auc: 0.948766\n",
      "[3500]\ttraining's binary_logloss: 0.324894\ttraining's auc: 0.950295\n",
      "[3600]\ttraining's binary_logloss: 0.321812\ttraining's auc: 0.951796\n",
      "[3700]\ttraining's binary_logloss: 0.318824\ttraining's auc: 0.953189\n",
      "[3800]\ttraining's binary_logloss: 0.315828\ttraining's auc: 0.954576\n",
      "[3900]\ttraining's binary_logloss: 0.312952\ttraining's auc: 0.95594\n",
      "[4000]\ttraining's binary_logloss: 0.310159\ttraining's auc: 0.957188\n",
      "[4100]\ttraining's binary_logloss: 0.307401\ttraining's auc: 0.958431\n",
      "[4200]\ttraining's binary_logloss: 0.304649\ttraining's auc: 0.95965\n",
      "[4300]\ttraining's binary_logloss: 0.301969\ttraining's auc: 0.960828\n",
      "[4400]\ttraining's binary_logloss: 0.299346\ttraining's auc: 0.961964\n",
      "[4500]\ttraining's binary_logloss: 0.296728\ttraining's auc: 0.963093\n",
      "[4600]\ttraining's binary_logloss: 0.294154\ttraining's auc: 0.96418\n",
      "[4700]\ttraining's binary_logloss: 0.291639\ttraining's auc: 0.965224\n",
      "[4800]\ttraining's binary_logloss: 0.289173\ttraining's auc: 0.966239\n",
      "[4900]\ttraining's binary_logloss: 0.286723\ttraining's auc: 0.967215\n",
      "[5000]\ttraining's binary_logloss: 0.284353\ttraining's auc: 0.968166\n",
      "[5100]\ttraining's binary_logloss: 0.282016\ttraining's auc: 0.969091\n",
      "[5200]\ttraining's binary_logloss: 0.279705\ttraining's auc: 0.969974\n",
      "[5300]\ttraining's binary_logloss: 0.277397\ttraining's auc: 0.970876\n",
      "[5400]\ttraining's binary_logloss: 0.275114\ttraining's auc: 0.971748\n",
      "[5500]\ttraining's binary_logloss: 0.272856\ttraining's auc: 0.972594\n",
      "[5600]\ttraining's binary_logloss: 0.270649\ttraining's auc: 0.973407\n",
      "[5700]\ttraining's binary_logloss: 0.268494\ttraining's auc: 0.974186\n",
      "[5800]\ttraining's binary_logloss: 0.266354\ttraining's auc: 0.97496\n",
      "[5900]\ttraining's binary_logloss: 0.264215\ttraining's auc: 0.975709\n",
      "[6000]\ttraining's binary_logloss: 0.262118\ttraining's auc: 0.97643\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'bossting_type':'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric':['binary_logloss','auc'],\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':180,\n",
    "    'min_data_in_leaf':1000,\n",
    "    'max_depth':10,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction':0.8,\n",
    "    'min_gain_to_split': 0,\n",
    "    'lambda_l1': 6,\n",
    "    'lambda_l2': 2000\n",
    "}\n",
    "evals_result={}\n",
    "gbm=lgbm.train(params,train_data,num_boost_round=6000,valid_sets=train_data,\n",
    "evals_result=evals_result,verbose_eval=100)\n",
    "feature_importance=pd.DataFrame({'name':gbm.feature_name(),'importance':gbm.feature_importance()}).sort_values(by='importance',ascending=False)\n",
    "feature_importance.to_csv('work/feature_importance/feat_importance_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as cPickle\n",
    "cPickle.dump(gbm,open('work/music_lightgbm/submit_B.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train=val_train[math.ceil(val_train.shape[0]*0.3):math.ceil(val_train.shape[0]*0.5)]\n",
    "test=val_test[:]\n",
    "test.drop(['target'],inplace=True,axis=1)\n",
    "train_y=train['target']\n",
    "train.drop(['target'],inplace=True,axis=1)\n",
    "train=train.merge(members,on='msno',how='left')\n",
    "test=test.merge(members,on='msno',how='left')\n",
    "train=train.merge(songs,on='song_id',how='left')\n",
    "test=test.merge(songs,on='song_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=lgbm.Dataset(train,label=train_y,free_raw_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.520656\ttraining's auc: 0.818297\n",
      "[200]\ttraining's binary_logloss: 0.495253\ttraining's auc: 0.839756\n",
      "[300]\ttraining's binary_logloss: 0.477835\ttraining's auc: 0.853433\n",
      "[400]\ttraining's binary_logloss: 0.464786\ttraining's auc: 0.863057\n",
      "[500]\ttraining's binary_logloss: 0.454002\ttraining's auc: 0.870683\n",
      "[600]\ttraining's binary_logloss: 0.44466\ttraining's auc: 0.877088\n",
      "[700]\ttraining's binary_logloss: 0.436426\ttraining's auc: 0.882675\n",
      "[800]\ttraining's binary_logloss: 0.428838\ttraining's auc: 0.887687\n",
      "[900]\ttraining's binary_logloss: 0.421701\ttraining's auc: 0.892317\n",
      "[1000]\ttraining's binary_logloss: 0.415105\ttraining's auc: 0.896537\n",
      "[1100]\ttraining's binary_logloss: 0.409001\ttraining's auc: 0.900332\n",
      "[1200]\ttraining's binary_logloss: 0.40315\ttraining's auc: 0.903976\n",
      "[1300]\ttraining's binary_logloss: 0.397585\ttraining's auc: 0.907392\n",
      "[1400]\ttraining's binary_logloss: 0.392336\ttraining's auc: 0.910536\n",
      "[1500]\ttraining's binary_logloss: 0.387373\ttraining's auc: 0.9135\n",
      "[1600]\ttraining's binary_logloss: 0.38254\ttraining's auc: 0.916333\n",
      "[1700]\ttraining's binary_logloss: 0.377793\ttraining's auc: 0.919078\n",
      "[1800]\ttraining's binary_logloss: 0.373269\ttraining's auc: 0.921648\n",
      "[1900]\ttraining's binary_logloss: 0.368907\ttraining's auc: 0.924113\n",
      "[2000]\ttraining's binary_logloss: 0.364633\ttraining's auc: 0.926504\n",
      "[2100]\ttraining's binary_logloss: 0.360539\ttraining's auc: 0.92876\n",
      "[2200]\ttraining's binary_logloss: 0.356491\ttraining's auc: 0.930963\n",
      "[2300]\ttraining's binary_logloss: 0.352562\ttraining's auc: 0.933081\n",
      "[2400]\ttraining's binary_logloss: 0.348751\ttraining's auc: 0.935118\n",
      "[2500]\ttraining's binary_logloss: 0.345018\ttraining's auc: 0.937058\n",
      "[2600]\ttraining's binary_logloss: 0.341417\ttraining's auc: 0.938912\n",
      "[2700]\ttraining's binary_logloss: 0.337859\ttraining's auc: 0.940749\n",
      "[2800]\ttraining's binary_logloss: 0.334384\ttraining's auc: 0.942493\n",
      "[2900]\ttraining's binary_logloss: 0.331033\ttraining's auc: 0.94418\n",
      "[3000]\ttraining's binary_logloss: 0.327763\ttraining's auc: 0.945792\n",
      "[3100]\ttraining's binary_logloss: 0.324532\ttraining's auc: 0.947383\n",
      "[3200]\ttraining's binary_logloss: 0.32139\ttraining's auc: 0.948908\n",
      "[3300]\ttraining's binary_logloss: 0.318275\ttraining's auc: 0.950368\n",
      "[3400]\ttraining's binary_logloss: 0.315213\ttraining's auc: 0.951818\n",
      "[3500]\ttraining's binary_logloss: 0.3122\ttraining's auc: 0.953214\n",
      "[3600]\ttraining's binary_logloss: 0.309255\ttraining's auc: 0.954581\n",
      "[3700]\ttraining's binary_logloss: 0.306348\ttraining's auc: 0.955906\n",
      "[3800]\ttraining's binary_logloss: 0.303527\ttraining's auc: 0.957163\n",
      "[3900]\ttraining's binary_logloss: 0.300755\ttraining's auc: 0.958408\n",
      "[4000]\ttraining's binary_logloss: 0.297984\ttraining's auc: 0.959635\n",
      "[4100]\ttraining's binary_logloss: 0.295293\ttraining's auc: 0.96081\n",
      "[4200]\ttraining's binary_logloss: 0.292661\ttraining's auc: 0.961936\n",
      "[4300]\ttraining's binary_logloss: 0.290047\ttraining's auc: 0.963027\n",
      "[4400]\ttraining's binary_logloss: 0.287504\ttraining's auc: 0.964103\n",
      "[4500]\ttraining's binary_logloss: 0.284942\ttraining's auc: 0.965162\n",
      "[4600]\ttraining's binary_logloss: 0.282472\ttraining's auc: 0.966165\n",
      "[4700]\ttraining's binary_logloss: 0.28004\ttraining's auc: 0.967135\n",
      "[4800]\ttraining's binary_logloss: 0.277663\ttraining's auc: 0.968086\n",
      "[4900]\ttraining's binary_logloss: 0.275318\ttraining's auc: 0.968994\n",
      "[5000]\ttraining's binary_logloss: 0.272988\ttraining's auc: 0.9699\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'bossting_type':'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric':['binary_logloss','auc'],\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':180,\n",
    "    'min_data_in_leaf':1000,\n",
    "    'max_depth':10,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction':0.8,\n",
    "    'min_gain_to_split': 0,\n",
    "    'lambda_l1': 6,\n",
    "    'lambda_l2': 2000\n",
    "}\n",
    "evals_result={}\n",
    "gbm=lgbm.train(params,train_data,num_boost_round=5000,valid_sets=train_data,\n",
    "evals_result=evals_result,verbose_eval=100)\n",
    "feature_importance=pd.DataFrame({'name':gbm.feature_name(),'importance':gbm.feature_importance()}).sort_values(by='importance',ascending=False)\n",
    "feature_importance.to_csv('work/feature_importance/feat_importance_C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as cPickle\n",
    "cPickle.dump(gbm,open('work/music_lightgbm/submit_C.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train=val_train[math.ceil(val_train.shape[0]*0.1):math.ceil(val_train.shape[0]*0.3)]\n",
    "test=val_test[:]\n",
    "test.drop(['target'],inplace=True,axis=1)\n",
    "train_y=train['target']\n",
    "train.drop(['target'],inplace=True,axis=1)\n",
    "train=train.merge(members,on='msno',how='left')\n",
    "test=test.merge(members,on='msno',how='left')\n",
    "train=train.merge(songs,on='song_id',how='left')\n",
    "test=test.merge(songs,on='song_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=lgbm.Dataset(train,label=train_y,free_raw_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'bossting_type':'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric':['binary_logloss','auc'],\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':180,\n",
    "    'min_data_in_leaf':1000,\n",
    "    'max_depth':10,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction':0.8,\n",
    "    'min_gain_to_split': 0,\n",
    "    'lambda_l1': 6,\n",
    "    'lambda_l2': 2000\n",
    "}\n",
    "evals_result={}\n",
    "gbm=lgbm.train(params,train_data,num_boost_round=5000,valid_sets=train_data,\n",
    "evals_result=evals_result,verbose_eval=100)\n",
    "feature_importance=pd.DataFrame({'name':gbm.feature_name(),'importance':gbm.feature_importance()}).sort_values(by='importance',ascending=False)\n",
    "feature_importance.to_csv('work/feature_importance/feat_importance_D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as cPickle\n",
    "cPickle.dump(gbm,open('work/music_lightgbm/submit_D.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as cPickle\n",
    "gbm_a=cPickle.load(open('work/music_lightgbm/submit_A.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_1=math.ceil(test.shape[0]*0.33)\n",
    "test_1=test[0:size_1]\n",
    "test_id_1=test_id[0:size_1]\n",
    "test_pred_1=gbm_a.predict(test_1)\n",
    "test_sub_1=pd.DataFrame({'id':tese_id_1,'target':test_pred_1})\n",
    "test_sub_1.to_csv('work/music_submit/submit_A_%.5f_01.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_1\n",
    "del test_id_1\n",
    "del test_pred_1\n",
    "gc.collect()\n",
    "size_2=math.ceil(test.shape[0]*0.66)\n",
    "test_2=test[size_1:size_2]\n",
    "test_id_2=test_id[size_1:size_2]\n",
    "test_pred_2=gbm_a.predict(test_2)\n",
    "test_sub_2=pd.DataFram({'id':test_id_2,'target':test_pred_2})\n",
    "test_sub_2.to_csv('work/music_submit/submit_A_%.5f_02.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_2\n",
    "del test_id_2\n",
    "del test_pred_2\n",
    "gc.collect()\n",
    "\n",
    "test_3=test[size_2]\n",
    "test_id_3=test_id[size_2:]\n",
    "test_pred_3=gbm_a.predict(test_3)\n",
    "test_sub_3=pd.DataFrame({'id':test_id_3,'target':test_pred_3})\n",
    "test_sub_3.to_csv('work/music_submit/submit_A_%.5f_03.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub=pd.concat([test_sub_1,test_sub_2,test_sub_3],axis=0)\n",
    "test_sub.to_csv('work/music_submit/submit_A_%.5f_123.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as cPickle\n",
    "gbm_b=cPickle.load(open('work/music_lightgbm/submit_B.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_1=math.ceil(test.shape[0]*0.33)\n",
    "test_1=test[0:size_1]\n",
    "test_id_1=test_id[0:size_1]\n",
    "test_pred_1=gbm_b.predict(test_1)\n",
    "test_sub_1=pd.DataFrame({'id':tese_id_1,'target':test_pred_1})\n",
    "test_sub_1.to_csv('work/music_submit/submit_B_%.5f_01.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_1\n",
    "del test_id_1\n",
    "del test_pred_1\n",
    "gc.collect()\n",
    "size_2=math.ceil(test.shape[0]*0.66)\n",
    "test_2=test[size_1:size_2]\n",
    "test_id_2=test_id[size_1:size_2]\n",
    "test_pred_2=gbm_b.predict(test_2)\n",
    "test_sub_2=pd.DataFram({'id':test_id_2,'target':test_pred_2})\n",
    "test_sub_2.to_csv('work/music_submit/submit_B_%.5f_02.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_2\n",
    "del test_id_2\n",
    "del test_pred_2\n",
    "gc.collect()\n",
    "\n",
    "test_3=test[size_2]\n",
    "test_id_3=test_id[size_2:]\n",
    "test_pred_3=gbm_b.predict(test_3)\n",
    "test_sub_3=pd.DataFrame({'id':test_id_3,'target':test_pred_3})\n",
    "test_sub_3.to_csv('work/music_submit/submit_B_%.5f_03.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub=pd.concat([test_sub_1,test_sub_2,test_sub_3],axis=0)\n",
    "test_sub.to_csv('work/music_submit/submit_B_%.5f_123.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as cPickle\n",
    "gbm_c=cPickle.load(open('work/music_lightgbm/submit_C.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_1=math.ceil(test.shape[0]*0.33)\n",
    "test_1=test[0:size_1]\n",
    "test_id_1=test_id[0:size_1]\n",
    "test_pred_1=gbm_c.predict(test_1)\n",
    "test_sub_1=pd.DataFrame({'id':tese_id_1,'target':test_pred_1})\n",
    "test_sub_1.to_csv('work/music_submit/submit_C_%.5f_01.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_1\n",
    "del test_id_1\n",
    "del test_pred_1\n",
    "gc.collect()\n",
    "size_2=math.ceil(test.shape[0]*0.66)\n",
    "test_2=test[size_1:size_2]\n",
    "test_id_2=test_id[size_1:size_2]\n",
    "test_pred_2=gbm_c.predict(test_2)\n",
    "test_sub_2=pd.DataFram({'id':test_id_2,'target':test_pred_2})\n",
    "test_sub_2.to_csv('work/music_submit/submit_C_%.5f_02.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_2\n",
    "del test_id_2\n",
    "del test_pred_2\n",
    "gc.collect()\n",
    "\n",
    "test_3=test[size_2]\n",
    "test_id_3=test_id[size_2:]\n",
    "test_pred_3=gbm_c.predict(test_3)\n",
    "test_sub_3=pd.DataFrame({'id':test_id_3,'target':test_pred_3})\n",
    "test_sub_3.to_csv('work/music_submit/submit_C_%.5f_03.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub=pd.concat([test_sub_1,test_sub_2,test_sub_3],axis=0)\n",
    "test_sub.to_csv('work/music_submit/submit_C_%.5f_123.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_1=math.ceil(test.shape[0]*0.33)\n",
    "test_1=test[0:size_1]\n",
    "test_id_1=test_id[0:size_1]\n",
    "test_pred_1=gbm_d.predict(test_1)\n",
    "test_sub_1=pd.DataFrame({'id':tese_id_1,'target':test_pred_1})\n",
    "test_sub_1.to_csv('work/music_submit/submit_D_%.5f_01.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_1\n",
    "del test_id_1\n",
    "del test_pred_1\n",
    "gc.collect()\n",
    "size_2=math.ceil(test.shape[0]*0.66)\n",
    "test_2=test[size_1:size_2]\n",
    "test_id_2=test_id[size_1:size_2]\n",
    "test_pred_2=gbm_d.predict(test_2)\n",
    "test_sub_2=pd.DataFram({'id':test_id_2,'target':test_pred_2})\n",
    "test_sub_2.to_csv('work/music_submit/submit_D_%.5f_02.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_2\n",
    "del test_id_2\n",
    "del test_pred_2\n",
    "gc.collect()\n",
    "\n",
    "test_3=test[size_2]\n",
    "test_id_3=test_id[size_2:]d\n",
    "test_pred_3=gbm_d.predict(test_3)\n",
    "test_sub_3=pd.DataFrame({'id':test_id_3,'target':test_pred_3})\n",
    "test_sub_3.to_csv('work/music_submit/submit_D_%.5f_03.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub=pd.concat([test_sub_1,test_sub_2,test_sub_3],axis=0)\n",
    "test_sub.to_csv('work/music_submit/submit_D_%.5f_123.csv'%(val_auc),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as cPickle\n",
    "gbm_d=cPickle.load(open('work/music_lightgbm/submit_D.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取四个训练好的模型预测的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv('work/music_submit/submit_A_%.5f_123.csv')\n",
    "b=pd.read_csv('work/music_submit/submit_B_%.5f_123.csv')\n",
    "c=pd.read_csv('work/music_submit/submit_C_%.5f_123.csv')\n",
    "d=pd.read_csv('work/music_submit/submit_D_%.5f_123.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1['target']=a['target']*0.6+b['target']*0.2+c['target']*0.1+d['target']*0.1\n",
    "a1.to_csv('work/music_submit/submit',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
